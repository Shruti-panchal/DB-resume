{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e9188f",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('final.csv')\n",
    "\n",
    "# Filter rows where Category is 'Data Science'\n",
    "data_science_rows = df[df['Category'] == 'Data Science']\n",
    "\n",
    "# Combine all skills related to Data Science into one string per resume\n",
    "data_science_skills = data_science_rows['skills'].str.cat(sep=' ')\n",
    "\n",
    "# Create a bag-of-words model\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([data_science_skills] + list(df['skills']))\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(X, X)\n",
    "\n",
    "# Get index of 'Data Science' category\n",
    "data_science_index = df[df['Category'] == 'Data Science'].index[0]\n",
    "\n",
    "# Get similarity scores for 'Data Science' category\n",
    "similarity_scores = cosine_sim[data_science_index]\n",
    "\n",
    "# Get indices of top N recommendations (excluding 'Data Science' itself)\n",
    "top_recommendations = similarity_scores.argsort()[:-1][::-1]\n",
    "\n",
    "# Extract skills for the top recommendations\n",
    "recommended_skills = df.loc[top_recommendations, 'skills'].tolist()\n",
    "\n",
    "# Display recommended skills\n",
    "print(\"Recommended Skills for Data Science:\")\n",
    "for skills in recommended_skills:\n",
    "    print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab9da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# from sklearn.feature_extraction.text import CountVectorizer \n",
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e657aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('finalll.csv')\n",
    "# df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b3777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_science_rows = df[df['Category'] == 'Data Science']\n",
    "# profile = input(\"Enter profile name you're aiming for : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fcb28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_rows= df[df['Category'] == profile]\n",
    "# # profile_rows = df[df['Category'] == data science]\n",
    "# profile_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5566d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# profile_skills = profile_rows['Skill'].str.cat(sep=' ')\n",
    "# profile_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0be6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform([profile_skills] + list(df['Skill']))\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf502baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_sim = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abdc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get index of 'Data Science' category\n",
    "# profile_index = df[df['Category'] == profile].index[0]\n",
    "# profile_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10af8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get similarity scores for 'Data Science' category\n",
    "# similarity_scores = cosine_sim[profile_index]\n",
    "# similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1358fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# top_recommendations = similarity_scores.argsort()[:-1][::-1]\n",
    "# top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2dbbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract skills for the top recommendations\n",
    "# recommended_skills = profile_rows.loc[profile_rows.index.isin(top_recommendations), 'Skill'].tolist()\n",
    "# recommended_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1175069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['Category'] == 'Testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3e45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f9102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for data preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f81b5598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Experience(months)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "      <td>['Pandas', 'Numpy', 'Scipy', 'SCikit-learn', '...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills  R  Python  SAP HANA  Tableau  SAP HANA...</td>\n",
       "      <td>['R', 'Python', 'SAP HANA', 'Tableau', 'SAP HA...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "      <td>['Python', 'Machine learning', 'Sklearn', 'Sci...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n B.Tech   Rayat and Bahr...</td>\n",
       "      <td>['Software Development: inception, requirement...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "      <td>['Programming Languages: Python, Java', 'Datab...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER PROFICIENCY   Basic: MS-Office (Power...</td>\n",
       "      <td>['MS Office', 'CPP', 'Android Developer', 'Man...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Computer Skills:   Proficient in MS office (Wo...</td>\n",
       "      <td>['Windows', 'MS Office', 'Insulation Resistanc...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Willingness to accept the challenges.  Positi...</td>\n",
       "      <td>['C', 'Windows 7-8/NT/XP', 'C++', 'Documentati...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n",
       "      <td>['MS Office', 'C', 'Portius (PCB Design)', 'Mu...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n",
       "      <td>['Windows XP/7/8/8.1/10', 'MySQL', 'Html', 'SQ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume  \\\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...   \n",
       "1    Data Science  Skills  R  Python  SAP HANA  Tableau  SAP HANA...   \n",
       "2    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...   \n",
       "3    Data Science  Education Details \\r\\n B.Tech   Rayat and Bahr...   \n",
       "4    Data Science  Skills * Programming Languages: Python (pandas...   \n",
       "..            ...                                                ...   \n",
       "157       Testing  COMPUTER PROFICIENCY   Basic: MS-Office (Power...   \n",
       "158       Testing  Computer Skills:   Proficient in MS office (Wo...   \n",
       "159       Testing   Willingness to accept the challenges.  Positi...   \n",
       "160       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...   \n",
       "161       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...   \n",
       "\n",
       "                                                 Skill  Experience(months)  \n",
       "0    ['Pandas', 'Numpy', 'Scipy', 'SCikit-learn', '...                  24  \n",
       "1    ['R', 'Python', 'SAP HANA', 'Tableau', 'SAP HA...                  12  \n",
       "2    ['Python', 'Machine learning', 'Sklearn', 'Sci...                  12  \n",
       "3    ['Software Development: inception, requirement...                  24  \n",
       "4    ['Programming Languages: Python, Java', 'Datab...                  24  \n",
       "..                                                 ...                 ...  \n",
       "157  ['MS Office', 'CPP', 'Android Developer', 'Man...                  12  \n",
       "158  ['Windows', 'MS Office', 'Insulation Resistanc...                   6  \n",
       "159  ['C', 'Windows 7-8/NT/XP', 'C++', 'Documentati...                   9  \n",
       "160  ['MS Office', 'C', 'Portius (PCB Design)', 'Mu...                   6  \n",
       "161  ['Windows XP/7/8/8.1/10', 'MySQL', 'Html', 'SQ...                  24  \n",
       "\n",
       "[162 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Assuming you have a list of resumes and skills\n",
    "\n",
    "# final = pd.read_csv('final.csv')\n",
    "\n",
    "# resumes = final['Resume'].tolist()\n",
    "# skills = final['Skill'].tolist()\n",
    "\n",
    "# # Combine user details with existing skills for training\n",
    "# user_details = input(\"Enter your details (profile/job title, skills, total experience): \")\n",
    "# all_data = resumes + [user_details]\n",
    "\n",
    "# # Convert text data to TF-IDF features\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(all_data)\n",
    "\n",
    "# # Assuming you have labels for each resume\n",
    "# labels = list(range(len(resumes)))\n",
    "\n",
    "# # Train the model\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X[:-1], labels)  # Exclude the user details for training\n",
    "\n",
    "# # User details to predict skills\n",
    "# user_data = vectorizer.transform([user_details])\n",
    "\n",
    "# # Predict skills for user details\n",
    "# predicted_labels = model.predict(user_data)\n",
    "# print(predicted_labels)\n",
    "\n",
    "# # Get the corresponding skills based on predicted labels\n",
    "# predicted_skills = [skills[i] for i in predicted_labels]\n",
    "# # print([skills[18] for i in predicted_labels])\n",
    "\n",
    "# # Provide recommendations\n",
    "# print(\"Recommended Skills: \", predicted_skills)\n",
    "final = pd.read_csv(\"final.csv\")\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad4f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your category/job title: Python Developer \n",
      "Enter your total experience in months: 24\n",
      "Enter your skills (comma-separated within square brackets []): django, flask, python\n",
      "No matching resumes found for the category 'Python Developer ' and experience '24' months.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MultinomialNB.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m---> 38\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], labels)  \u001b[38;5;66;03m# Exclude the user details for training\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# User details to predict skills\u001b[39;00m\n\u001b[0;32m     41\u001b[0m user_data \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform([user_details])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:745\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    746\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    748\u001b[0m     labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:578\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    577\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39mreset)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:969\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    972\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    976\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MultinomialNB."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Assuming you have a list of resumes and skills\n",
    "final = pd.read_csv('final.csv')\n",
    "\n",
    "resumes = final['Resume'].tolist()\n",
    "skills = final['Skill'].tolist()\n",
    "categories = final['Category'].tolist()\n",
    "experience = final['Experience(months)'].tolist()\n",
    "\n",
    "# User inputs\n",
    "user_category = input(\"Enter your category/job title: \")\n",
    "user_experience = int(input(\"Enter your total experience in months: \"))\n",
    "user_skills = input(\"Enter your skills (comma-separated within square brackets []): \").strip('[]').split(',')\n",
    "\n",
    "# Filter data based on user input\n",
    "filtered_data = final[(final['Category'] == user_category) & (final['Experience(months)'] <= user_experience)]\n",
    "\n",
    "if filtered_data.empty:\n",
    "    print(f\"No matching resumes found for the category '{user_category}' and experience '{user_experience}' months.\")\n",
    "    exit()\n",
    "\n",
    "# Combine user details with existing skills for training\n",
    "user_details = f\"{user_category}, {', '.join(user_skills)}, {user_experience}\"\n",
    "all_data = filtered_data['Resume'].tolist() + [user_details]\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(all_data)\n",
    "\n",
    "# Assuming you have labels for each resume\n",
    "labels = list(range(len(filtered_data)))\n",
    "\n",
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X[:-1], labels)  # Exclude the user details for training\n",
    "\n",
    "# User details to predict skills\n",
    "user_data = vectorizer.transform([user_details])\n",
    "\n",
    "# Predict skills for user details\n",
    "predicted_labels = model.predict(user_data)\n",
    "\n",
    "# Get the corresponding skills based on predicted labels\n",
    "predicted_skills = [skills[i] for i in predicted_labels]\n",
    "\n",
    "# Provide recommendations\n",
    "if predicted_skills:\n",
    "    print(\"Recommended Skills: \", predicted_skills)\n",
    "else:\n",
    "    print(\"Pass your skills. No matching skills found for the given category and experience.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36057fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# # Assuming you have a list of resumes and skills\n",
    "# final = pd.read_csv('final.csv')\n",
    "\n",
    "# resumes = final['Resume'].tolist()\n",
    "# skills = final['Skill'].tolist()\n",
    "\n",
    "# # Get user details\n",
    "# user_job_category = input(\"Enter your job category: \")\n",
    "# user_skills = input(\"Enter your skills (comma-separated): \")\n",
    "# user_experience = int(input(\"Enter your total experience (in months): \"))\n",
    "\n",
    "# # Filter data based on user input\n",
    "# filtered_data = final[(final['Category'] == user_job_category) & (final['Experience(months)'] <= user_experience)]\n",
    "\n",
    "# # Combine user details with existing skills for training\n",
    "# user_details = f\"{user_job_category} {user_skills} {user_experience} months\"\n",
    "# all_data = filtered_data['Resume'].tolist() + [user_details]\n",
    "\n",
    "# # Convert text data to TF-IDF features\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(all_data)\n",
    "\n",
    "# # Assuming you have labels for each resume\n",
    "# labels = list(range(len(filtered_data)))\n",
    "\n",
    "# # Train the model\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X[:-1], labels)  # Exclude the user details for training\n",
    "\n",
    "# # User details to predict skills\n",
    "# user_data = vectorizer.transform([user_details])\n",
    "\n",
    "# # Predict skills for user details\n",
    "# predicted_labels = model.predict(user_data)\n",
    "\n",
    "# # Get the corresponding skills based on predicted labels\n",
    "# predicted_skills = [skills[i] for i in predicted_labels]\n",
    "\n",
    "# # Identify skills absent in user's resume\n",
    "# user_skills_list = user_skills.split(', ')\n",
    "# missing_skills = [skill for skill in predicted_skills if skill not in user_skills_list]\n",
    "\n",
    "# # Provide recommendations\n",
    "# print(\"Recommended Skills: \", missing_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bab2d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hr = df[df['Category']=='HR']\n",
    "# hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c426cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate resumes and skills\n",
    "# resumes = df['Resume'].tolist()\n",
    "# skills = df['Skill'].tolist()\n",
    "\n",
    "# # Combine user details with existing skills for training\n",
    "# all_data = resumes\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2418ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert text data to TF-IDF features\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(all_data)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c71ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have labels for each resume\n",
    "# labels = list(range(len(resumes)))\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eec1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cb23903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get user details through input form\n",
    "# user_details = input(\"Enter your details (profile/job title, skills, total experience): \")\n",
    "# user_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71ae2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # User details to predict skills\n",
    "# user_data = vectorizer.transform([user_details])\n",
    "# user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50a9fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict skills for user details\n",
    "# predicted_labels = model.predict(user_data)\n",
    "# predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8aee9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the corresponding skills based on predicted labels\n",
    "# predicted_skills = [skills[i] for i in predicted_labels]\n",
    "# print([skills[99] for i in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b79a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in predicted_labels:\n",
    "#     print(skill[i])\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "418a8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Provide recommendations\n",
    "# print(\"Recommended Skills: \", predicted_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fe46f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate resumes and skills\n",
    "# resumes = df['Resume'].tolist()\n",
    "# skills = df['Skill'].tolist()\n",
    "\n",
    "# # Combine user details with existing skills for training\n",
    "# all_data = resumes\n",
    "\n",
    "# # Convert text data to TF-IDF features\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(all_data)\n",
    "\n",
    "# # Assuming you have labels for each resume\n",
    "# labels = list(range(len(resumes)))\n",
    "\n",
    "# # Train the model\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X, labels)\n",
    "\n",
    "# # Get user details through input form\n",
    "# user_details = input(\"Enter your details (profile/job title, skills, total experience): \")\n",
    "\n",
    "# # User details to predict skills\n",
    "# user_data = vectorizer.transform([user_details])\n",
    "\n",
    "# # Predict skills for user details\n",
    "# predicted_labels = model.predict(user_data)\n",
    "\n",
    "# # Get the corresponding skills based on predicted labels\n",
    "# predicted_skills = [skills[i] for i in predicted_labels]\n",
    "\n",
    "# # Provide recommendations\n",
    "# print(\"Recommended Skills: \", predicted_skills)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d519c5f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
